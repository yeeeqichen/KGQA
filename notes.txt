2021/3/11: 修复了模型loss计算存在的问题，调整为l2范数并加入margin，计算公式为: score = margin - distance_r(h, t), loss = mean(-log(sigmoid(score)))
2021/3/12: （1）修复了KG_embed模型存在的grad问题，在第二阶段的训练中不再更新KG_embed模型的参数;
           （2）加入模型训练参数的保存，将日志写入文件；
           （3）修改relation预测方式，改进为softmax（scores）作为组合系数对KG_embed.rel_embeddings.weight进行线性组合（实验证明效果不如sigmoid）
2021/3/15: 在loss项中增加了negative部分，目前是naive的随机采样版本，实验证明训练效果有提升，后期可针对这一部分进一步优化
2021/3/16: （1）增加了对已训练模型的继续训练功能，可在表现较好的模型上进一步调优
           （2）增加了画图部分，对训练的过程进行可视化
2021/3/18: 进一步完善画图模块
2021/3/21：增加对其他embed模型的支持(complEx,实验表明效果不如rotatE(暂时))
2021/3/24: 使用聚类方法来对答案进行剪枝，生成候选答案集合，提高计算效率，***实验证明在提升效率的同时会损失一定的准确率***
2021/3/28：(1)改进question embed方法, 将question中的【head】统一替换为 xxx
           (2)统计训练过程中的gradient的范数，用于作为梯度裁剪的依据
2021/3/29: 增加对distmult的支持

2021/3/30: 改进relation预测方式，增加entity与relation的关联得分
2021/3/31: 更改模型结构，roberta部分参数不再进行微调（计算资源有限），而是将之作为embedding模块，精化后续的模块用于预测relation  ***取得新的最佳***

2021/4/2: 为了应对gradient vanishing，需要更新负采样策略（初步完成）, ***取得新的最佳***

2021/4/3: 增加了attention模块

2021/4/7: 增加了对attention的可视化，后续进一步调研attention主流方法；

2021/4/8: 实现self attention方法

2021/4/13: 完成中期报告

2021/4/15: 使用cache，支持更大的batch_size,加速实验


接下来工作：（1）规划一下接下来的实验，有计划的搜集实验数据
          （2）增加对答案的rerank，看能不能提升表现

embed模型
rotate:
no type constraint results:   metric:                  MRR             MR              hit@10          hit@3           hit@1
                              l(raw):                  0.281431        200.981995      0.548101        0.330784        0.152935
                              r(raw):                  0.722377        2.071288        0.989147        0.864085        0.561174
                              averaged(raw):           0.501904        101.526642      0.768624        0.597435        0.357055
                              l(filter):               0.983259        1.051061        0.999753        0.995807        0.970893
                              r(filter):               0.974402        1.061174        1.000000        0.997780        0.952639
                              averaged(filter):        0.978831        1.056117        0.999877        0.996793        0.961766
              0.999877
              0.9998766779899597

complex:
no type constraint results:    metric:                  MRR             MR              hit@10          hit@3           hit@1
                               l(raw):                  0.262771        664.490112      0.527380        0.312284        0.139369
                               r(raw):                  0.534176        3.325604        0.965466        0.663296        0.340898
                               averaged(raw):           0.398473        333.907867      0.746423        0.487790        0.240133
                               l(filter):               0.594383        470.665771      0.691416        0.646275        0.531327
                               r(filter):               0.623652        2.472373        0.990380        0.836704        0.441293
                               averaged(filter):        0.609018        236.569077      0.840898        0.741490        0.486310
               0.840898
               0.8408979177474976

transe:
no type constraint results:     metric:                  MRR             MR              hit@10          hit@3           hit@1
                                l(raw):                  0.284506        254.160828      0.541934        0.333744        0.160335
                                r(raw):                  0.733613        2.027874        0.990627        0.872472        0.579921
                                averaged(raw):           0.509059        128.094345      0.766280        0.603108        0.370128
                                l(filter):               0.897333        59.073509       0.923286        0.904292        0.883818
                                r(filter):               0.986489        1.031574        1.000000        0.999507        0.974840
                                averaged(filter):        0.941911        30.052542       0.961643        0.951899        0.929329
                0.961643
                0.961642861366272

模型：                                             Best Performance
roberta(fine-tune):                         Hits_1: 0.7364891913530824, Hits_3: 0.8668935148118495, Hist_10: 0.9367493995196157
roberta(fine-tune) + DNN:                   Hits_1: 0.7365892714171337, Hits_3: 0.8676941553242594, Hist_10: 0.9377502001601281
roberta(freeze) + DNN:                      Hits_1: 0.7556044835868695, Hits_3: 0.8722978382706165, Hist_10: 0.9412530024019216
roberta(fine-tune) + Attention*             Hits_1: 0.7391857485988791, Hits_3: 0.847177742193755, Hist_10: 0.9195356285028022
roberta(fine-tune) + Self Attention         Hits_1: 0.7419935948759008, Hits_3: 0.8626901521216973, Hist_10: 0.9362489991993594
这几个对比可见DNN、Attention对该模型的表现具有促进作用，并且fine-tune语言模型引入过多参数和负担，现有的计算条件下无法满足
roberta(freeze) + Attention* + DNN          Hits_1: 0.7692153722978383, Hits_3: 0.8872097678142514, Hist_10: 0.9464571657325861
roberta(freeze) + Self Attention + DNN      Hits_1: 0.7453963170536431, Hits_3: 0.8694955964771818, Hist_10: 0.9413530824659728

bert(fine-tune):
bert(freeze) + DNN:                         Hits_1: 0.7473979183346677, Hits_3: 0.8694955964771818, Hist_10: 0.9421537229783827
bert(freeze) + Attention* + DNN             Hits_1: 0.7593074459567654, Hits_3: 0.8730984787830264, Hist_10: 0.9402522017614091
bert(freeze) + Self Attention + DNN         Hits_1: 0.7822257806244995, Hits_3: 0.8884107285828663, Hist_10: 0.9479583666933546

LSTM(2-layer, 单向, 下同):                   Hits_1: 0.7426941553242594, Hits_3: 0.8561849479583667, Hist_10: 0.9299439551641313
LSTM + DNN:                                 Hits_1: 0.7690152121697358, Hits_3: 0.883706965572458,  Hist_10: 0.9466573258606885
LSTM + Attention* + DNN                     Hits_1: 0.7464971977582066, Hits_3: 0.881204963971177, Hist_10: 0.9512610088070457
LSTM + Self Attention + DNN                 Hits_1: 0.7315852682145717, Hits_3: 0.8576861489191353, Hist_10: 0.9342473979183347

LSTM(2-layer, 双向) + Self Attention + DNN
LSTM(4-layer, 单向) + DNN                    Hits_1: 0.7494995996797438, Hits_3: 0.8648919135308246, Hist_10: 0.9365492393915132

RotateE + ...              (4.18 --9:36)    Hits_1: 0.7822257806244995, Hits_3: 0.8884107285828663, Hist_10: 0.9479583666933546
ComplEx + ...                               Hits_1: 0.18885108086469177, Hits_3: 0.3925140112089672, Hist_10: 0.6015812650120096
DistMult + ...                              Hits_1: 0.08967173738991192, Hits_3: 0.16323058446757405, Hist_10: 0.25120096076861487
TransE + ...                                Hits_1: 0.6905524419535628, Hits_3: 0.8553843074459567, Hist_10: 0.942253803042434



